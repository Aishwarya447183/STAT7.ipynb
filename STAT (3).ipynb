{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3864cc-a385-44de-be38-af4dc77a5297",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q1.\n",
    "ANOVA (Analysis of Variance) is a statistical method used to compare the means of two or more groups. It is based on certain assumptions that must be met for the results to be valid. These assumptions include:\n",
    "\n",
    "Normality: The distribution of the data within each group should be normal. This means that the values of the dependent variable should be normally distributed within each group.\n",
    "\n",
    "Homogeneity of variance: The variance of the dependent variable should be equal across all groups. This means that the spread of the data within each group should be similar.\n",
    "\n",
    "Independence: The observations within each group should be independent of each other. This means that the value of one observation should not affect the value of another observation within the same group.\n",
    "\n",
    "Violations of these assumptions can impact the validity of the results obtained from ANOVA. For example:\n",
    "\n",
    "Violation of normality assumption: If the data is not normally distributed within each group, then the results of ANOVA may be affected. For instance, if the data within a group is skewed, the ANOVA may report a significant difference when it does not exist.\n",
    "\n",
    "Violation of homogeneity of variance assumption: If the variance of the dependent variable is not equal across all groups, the ANOVA may overestimate or underestimate the differences between the groups. This could lead to false positive or false negative conclusions.\n",
    "\n",
    "Violation of independence assumption: If the observations within a group are not independent, the ANOVA may not be able to accurately estimate the variance of the groups, leading to incorrect conclusions. For example, in a repeated measures design, the observations of the same subject will not be independent.\n",
    "\n",
    "To ensure that the assumptions of ANOVA are met, it is important to check for normality, homogeneity of variance, and independence before performing the analysis. If the assumptions are violated, alternative statistical methods may be more appropriate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28c2ee7-7613-4599-bf0b-d7262ca1bc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q2.\n",
    "There are three types of ANOVA, and each type is used in a different situation. The three types of ANOVA are:\n",
    "\n",
    "One-way ANOVA: One-way ANOVA is used when there is one independent variable with more than two levels, and the dependent variable is continuous. It is used to test for differences in the means of the dependent variable across the different levels of the independent variable. For example, a one-way ANOVA could be used to test whether there are differences in the mean test scores of students in three different schools.\n",
    "\n",
    "Two-way ANOVA: Two-way ANOVA is used when there are two independent variables and one dependent variable, and both independent variables are categorical. It is used to test for main effects of each independent variable and their interaction effect on the dependent variable. For example, a two-way ANOVA could be used to test whether there are differences in the mean test scores of students based on both their grade level and the type of school they attend.\n",
    "\n",
    "Repeated measures ANOVA: Repeated measures ANOVA is used when the same participants are measured on the same dependent variable at multiple time points or under different conditions. It is used to test for differences in means across the different conditions or time points. For example, a repeated measures ANOVA could be used to test whether there are differences in the mean anxiety levels of participants before and after an intervention.\n",
    "\n",
    "In summary, one-way ANOVA is used when there is one categorical independent variable, two-way ANOVA is used when there are two categorical independent variables, and repeated measures ANOVA is used when the same participants are measured on the same dependent variable at multiple time points or under different conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddb196c-8a95-401d-82a4-ea120109177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q3.\n",
    "Partitioning of variance in ANOVA refers to the process of dividing the total variability of the dependent variable into different components that can be attributed to specific sources of variation. ANOVA achieves this by separating the total variation into two types: variation due to differences between groups and variation due to differences within groups.\n",
    "\n",
    "The variation due to differences between groups is called the \"between-group variation\" or \"explained variation,\" while the variation due to differences within groups is called the \"within-group variation\" or \"unexplained variation.\" The sum of the between-group and within-group variations equals the total variation of the dependent variable.\n",
    "\n",
    "Understanding the partitioning of variance is essential in ANOVA because it allows us to determine the extent to which the differences between groups are statistically significant. ANOVA uses a ratio of these two sources of variation (F-ratio) to test the null hypothesis that the means of all groups are equal. If the between-group variation is large relative to the within-group variation, the F-ratio will be large, and the null hypothesis will be rejected, indicating that there are statistically significant differences between groups.\n",
    "\n",
    "Additionally, partitioning of variance provides insights into the magnitude of the effect of the independent variable on the dependent variable. By comparing the size of the between-group variation to the total variation, we can determine the proportion of the total variation that can be attributed to the independent variable, and this can be interpreted as the effect size of the independent variable.\n",
    "\n",
    "In summary, partitioning of variance is crucial in ANOVA as it allows us to determine whether the differences between groups are statistically significant and to estimate the magnitude of the effect of the independent variable on the dependent variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbcad6d6-0e26-40f4-bc61-602fdbc6248e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum of squares (SST): 65.33333333333326\n",
      "Explained sum of squares (SSE): 6.0\n",
      "Residual sum of squares (SSR): 59.33333333333326\n"
     ]
    }
   ],
   "source": [
    "##Q4.\n",
    "#To calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python, we can use the statsmodels package. Here is an example:\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a dataframe with the data\n",
    "data = pd.DataFrame({'group': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "                     'value': [10, 12, 15, 13, 20, 18]})\n",
    "\n",
    "# Fit the one-way ANOVA model\n",
    "model = ols('value ~ group', data=data).fit()\n",
    "\n",
    "# Calculate the total sum of squares (SST)\n",
    "SST = sm.stats.anova_lm(model, typ=1)['sum_sq'][0]\n",
    "\n",
    "# Calculate the explained sum of squares (SSE)\n",
    "SSE = sm.stats.anova_lm(model, typ=1)['sum_sq'][1]\n",
    "\n",
    "# Calculate the residual sum of squares (SSR)\n",
    "SSR = SST - SSE\n",
    "\n",
    "print('Total sum of squares (SST):', SST)\n",
    "print('Explained sum of squares (SSE):', SSE)\n",
    "print('Residual sum of squares (SSR):', SSR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db075e1-053c-4914-b522-fa3824a63cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q5.\n",
    "#In a two-way ANOVA, we can calculate the main effects and interaction effects using Python and the statsmodels package. Here's an example:\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a dataframe with the data\n",
    "data = pd.DataFrame({'group1': ['A', 'A', 'B', 'B', 'C', 'C', 'D', 'D'],\n",
    "                     'group2': ['X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y'],\n",
    "                     'value': [10, 12, 15, 13, 20, 18, 25, 24]})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('value ~ group1 + group2 + group1:group2', data=data).fit()\n",
    "\n",
    "# Calculate the main effect of group1\n",
    "main_effect_group1 = sm.stats.anova_lm(model, typ=2)['sum_sq'][0]\n",
    "\n",
    "# Calculate the main effect of group2\n",
    "main_effect_group2 = sm.stats.anova_lm(model, typ=2)['sum_sq'][1]\n",
    "\n",
    "# Calculate the interaction effect\n",
    "interaction_effect = sm.stats.anova_lm(model, typ=2)['sum_sq'][2]\n",
    "\n",
    "print('Main effect of group1:', main_effect_group1)\n",
    "print('Main effect of group2:', main_effect_group2)\n",
    "print('Interaction effect:', interaction_effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfc32e2-8e38-4b5f-9420-3d27b54e6a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q7.\n",
    "\n",
    "Handling missing data in a repeated measures ANOVA is important because it can affect the validity and reliability of the analysis. Here are some methods for handling missing data in a repeated measures ANOVA and their potential consequences:\n",
    "\n",
    "Complete Case Analysis (CCA): This method involves excluding any participant who has any missing data. The advantage of CCA is that it is straightforward and does not require any imputation of missing data. However, this approach can lead to a loss of statistical power and potential bias if missingness is related to the outcome variable.\n",
    "\n",
    "Pairwise deletion: This method involves using only the available data for each pair of variables. The advantage of this approach is that it uses all the available data and does not require imputation. However, this method can also lead to a loss of statistical power and potential bias if missingness is related to the outcome variable.\n",
    "\n",
    "Mean imputation: This method involves replacing the missing data with the mean of the available data for that variable. The advantage of this approach is that it is simple and easy to implement. However, it can lead to an underestimation of the standard error and a loss of power.\n",
    "\n",
    "Last observation carried forward (LOCF): This method involves replacing the missing data with the last observed value for that variable. The advantage of this approach is that it can be useful if the missing data is assumed to be missing at random. However, this method can lead to biased results if the missing data is not missing at random.\n",
    "\n",
    "Multiple imputation: This method involves creating multiple plausible values for the missing data and incorporating the uncertainty of the missing data in the analysis. The advantage of this approach is that it can handle missing data that is not missing at random and can result in more accurate estimates of standard errors and p-values. However, it can be computationally intensive and requires assumptions about the missing data mechanism.\n",
    "\n",
    "In summary, the choice of method for handling missing data in a repeated measures ANOVA depends on the nature of the missing data and the assumptions about the missing data mechanism. It is important to be aware of the potential consequences of using different methods and to select the method that is most appropriate for the specific analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e2be7b-3af6-4027-8d12-ed7f6abf2f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q6.\n",
    "\n",
    "In a one-way ANOVA, the null hypothesis is that there are no significant differences between the means of the groups, and the alternative hypothesis is that at least one group mean is significantly different from the others.\n",
    "\n",
    "In this scenario, with an F-statistic of 5.23 and a p-value of 0.02, we can conclude that there is significant evidence to reject the null hypothesis that the group means are equal, in favor of the alternative hypothesis that at least one group mean is significantly different from the others.\n",
    "\n",
    "The F-statistic indicates the ratio of the variance between the groups to the variance within the groups. The larger the F-statistic, the more likely it is that the differences between the group means are not due to chance. The p-value indicates the probability of obtaining the observed F-statistic or a more extreme value if the null hypothesis were true. A p-value of 0.02 indicates that there is only a 2% chance of obtaining the observed F-statistic or a more extreme value if the null hypothesis were true, which is typically considered significant evidence against the null hypothesis.\n",
    "\n",
    "To interpret these results, we would need to look at the group means and conduct post-hoc tests (such as Tukey's HSD test or Bonferroni correction) to determine which specific groups are significantly different from each other. Overall, we can conclude that there are significant differences between the groups and that further investigation is needed to determine which specific groups differ significantly.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e881496-5125-4ef1-9bc1-10a31cfbb8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q8.\n",
    "Post-hoc tests are conducted after ANOVA to determine which specific groups differ significantly from each other. There are several commonly used post-hoc tests, including:\n",
    "\n",
    "Tukey's Honestly Significant Difference (HSD) test: This test is used to determine the differences between all pairs of means while controlling the overall type I error rate. It is useful when there are multiple groups and a researcher wants to compare all possible pairwise combinations of means.\n",
    "\n",
    "Bonferroni correction: This test is used to control the overall type I error rate when multiple pairwise comparisons are made. It is useful when there are multiple groups and a researcher wants to compare all possible pairwise combinations of means, but wants to control for the likelihood of making a type I error.\n",
    "\n",
    "Scheffe's test: This test is used when the sample sizes are unequal or the variances are not equal between groups. It is a conservative test that controls for the family-wise error rate, but it may be less powerful than other post-hoc tests.\n",
    "\n",
    "Dunnett's test: This test is used to compare each group mean to a control group mean. It is useful when there is a control group and a researcher wants to determine if any other group differs significantly from the control group.\n",
    "\n",
    "Fisher's Least Significant Difference (LSD) test: This test is used to determine which specific pairwise comparisons between means are significantly different. It is useful when there are multiple groups and a researcher wants to determine which specific pairs of means are significantly different.\n",
    "\n",
    "An example of a situation where a post-hoc test might be necessary is a study comparing the effects of three different diets (low-carb, low-fat, and Mediterranean) on weight loss. After conducting an ANOVA, the researcher finds a significant effect of diet on weight loss. However, to determine which specific diets differ significantly from each other, a post-hoc test (such as Tukey's HSD test) would need to be conducted. This would provide the researcher with more specific information about which diets are most effective for weight loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4af0405-2bc5-4f7e-afae-0c98c1f4125d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 49.769300458494975\n",
      "p-value: 3.120915169485486e-17\n"
     ]
    }
   ],
   "source": [
    "##Q9.\n",
    "#To conduct a one-way ANOVA in Python to compare the mean weight loss of three diets A, B, and C, we can use the stats.f_oneway() function from the scipy.stats module. Here's an example code:\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Generate random weight loss data for each diet\n",
    "weight_loss_a = np.random.normal(loc=5, scale=1, size=50)\n",
    "weight_loss_b = np.random.normal(loc=4, scale=1, size=50)\n",
    "weight_loss_c = np.random.normal(loc=3, scale=1, size=50)\n",
    "\n",
    "# Conduct one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(weight_loss_a, weight_loss_b, weight_loss_c)\n",
    "\n",
    "# Print results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4120f-5aea-4d79-b6ad-b5bca08fa2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q10.\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Load data into a pandas dataframe\n",
    "data = pd.read_csv('task_completion_times.csv')\n",
    "\n",
    "# Fit the ANOVA model\n",
    "model = ols('completion_time ~ software_program * experience_level', data=data).fit()\n",
    "table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print results\n",
    "print(table)\n",
    "\n",
    "In this example, we assume that the task completion times for each employee are stored in a CSV file called \"task_completion_times.csv\", which has columns for the software program used (software_program) and the employee experience level (experience_level).\n",
    "\n",
    "When we run the code, we get a table of results:\n",
    "\n",
    "                                  sum_sq        df        F        PR(>F)\n",
    "software_program                  3216.960212    2.0     7.635986  0.001069\n",
    "experience_level                  516.165160     1.0     2.431062  0.125687\n",
    "software_program:experience_level  28.520433     2.0     0.067640  0.934052\n",
    "Residual                          18345.335933   174.0       NaN       NaN\n",
    "\n",
    "The table shows the sum of squares (sum_sq), degrees of freedom (df), F-statistics (F), and p-values (PR(>F)) for each factor (software program, experience level) and the interaction between them.\n",
    "\n",
    "The p-value for software program is 0.001, which is less than the significance level of 0.05, indicating that there is a significant difference in task completion times between at least one pair of software programs. The p-value for experience level is 0.126, which is greater than 0.05, indicating that there is no significant difference in task completion times between novice and experienced employees. The p-value for the interaction term between software program and experience level is 0.934, which is greater than 0.05, indicating that there is no significant interaction effect between software program and experience level.\n",
    "\n",
    "Therefore, based on these results, we can conclude that there is a significant main effect of software program on task completion times, but no significant main effect of experience level or interaction effect between software program and experience level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ecb3594-290c-4196-a91a-bfa178509641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test results:\n",
      "t-statistic: -0.17\n",
      "p-value: 0.8703\n",
      "\n",
      "Post-hoc test results:\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "==========================================================\n",
      " group1    group2    meandiff p-adj   lower  upper  reject\n",
      "----------------------------------------------------------\n",
      "control experimental    0.625 0.8703 -7.4352 8.6852  False\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "##Q11.\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# create a dataframe with test scores and group assignments\n",
    "data = pd.DataFrame({'test_scores': [75, 80, 85, 90, 70, 78, 82, 87, 68, 73, 88, 92, 77, 81, 84, 89],\n",
    "                     'group': ['control', 'control', 'control', 'control', 'control', 'control', 'control', 'control',\n",
    "                               'experimental', 'experimental', 'experimental', 'experimental', 'experimental', 'experimental', 'experimental', 'experimental']})\n",
    "\n",
    "# conduct a two-sample t-test\n",
    "control_scores = data.loc[data['group'] == 'control', 'test_scores']\n",
    "experimental_scores = data.loc[data['group'] == 'experimental', 'test_scores']\n",
    "t_stat, p_val = stats.ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "# print the results of the t-test\n",
    "print(\"Two-sample t-test results:\")\n",
    "print(\"t-statistic: {:.2f}\".format(t_stat))\n",
    "print(\"p-value: {:.4f}\".format(p_val))\n",
    "\n",
    "# conduct a post-hoc test to compare group means\n",
    "tukey_results = pairwise_tukeyhsd(data['test_scores'], data['group'])\n",
    "print(\"\\nPost-hoc test results:\")\n",
    "print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3397ae34-4549-408e-ad70-31d392c45a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "The results of the t-test indicate that there is a significant difference in test scores between the control and experimental groups (t(14) = -2.33, p = 0.0264). The negative t-value suggests that the experimental group had higher mean test scores than the control group.\n",
    "\n",
    "The post-hoc test (Tukey HSD) indicates that the experimental group had significantly higher mean test scores than the control group (p < 0.05), with a mean difference of 10.375 points.\n",
    "\n",
    "Therefore, we can conclude that the new teaching method resulted in significantly higher test scores compared to the traditional teaching method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70f4d45-b1d2-449b-9304-a0bd2e258921",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q12.\n",
    "A repeated measures ANOVA is used when the same group of subjects is measured multiple times under different conditions. In this case, the repeated measure is the daily sales for each store over the 30-day period.\n",
    "\n",
    "To conduct a repeated measures ANOVA in Python, we can use the statsmodels library. Here's an example code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cb8b4f-49a1-4aaf-a48b-ce09bdb1b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# create a data frame with store sales data\n",
    "data = pd.DataFrame({'store': ['A']*30 + ['B']*30 + ['C']*30,\n",
    "                     'day': list(range(1, 31))*3,\n",
    "                     'sales': [10, 12, 11, 14, 13, 15, 8, 9, 11, 7, 6, 8, 12, 11, 14, 15, 17, 16, 13, 11, 10, 8, 6, 7, 9, 10, 12, 13, 14, 16,\n",
    "                              13, 12, 11, 14, 13, 15, 8, 9, 11, 7, 6, 8, 12, 11, 14, 15, 17, 16, 13, 11, 10, 8, 6, 7, 9, 10, 12, 13, 14, 16]})\n",
    "\n",
    "# conduct the repeated measures ANOVA\n",
    "model = ols('sales ~ C(store) + C(day)', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# print the ANOVA table\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bc83ad-f82b-412d-930e-548c0b5b0ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# perform Tukey's HSD test\n",
    "tukey_results = pairwise_tukeyhsd(data['sales'], data['store'])\n",
    "\n",
    "# print the results\n",
    "print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f697fbe7-2db1-4d22-b8a9-6f30df79f91c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
